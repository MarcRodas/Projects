{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l__aoHxEoi55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ab01dc4-9990-4b5e-886e-200487ec4a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade transformers\n",
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import csv\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tabulate import tabulate\n",
        "from tqdm import trange\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModel\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Verificar si hay una GPU disponible\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "mkzd3rD1pg3g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getData(bs, transform_train, transform_test):\n",
        "  # Download dataset and define data loader\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=True, num_workers=2)\n",
        "\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "  num_classes = 10\n",
        "  return trainset, trainloader, testset, testloader, num_classes"
      ],
      "metadata": {
        "id": "hJUDxx-mq7E1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getAugmentation(img_size):\n",
        "  transform_train = transforms.Compose([\n",
        "      transforms.Resize((img_size,img_size)),\n",
        "      transforms.RandomCrop(img_size, padding=img_size//8),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      #transforms.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784)),\n",
        "  ])\n",
        "\n",
        "  transform_test = transforms.Compose([\n",
        "      transforms.Resize((img_size,img_size)),\n",
        "      transforms.ToTensor(),\n",
        "      #transforms.Normalize((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784)),\n",
        "  ])\n",
        "\n",
        "  return transform_train,transform_test"
      ],
      "metadata": {
        "id": "rqMflMieCYHZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224\n",
        "img_channels=3\n",
        "\n",
        "# Training params\n",
        "bs = 32 # batch size\n",
        "epochs = 100 # total training epochs\n",
        "load_check = False # to load a checkpoint\n",
        "patch_size= 16 # patch size (square)\n",
        "d_model=768 # dimensionality transformer representation"
      ],
      "metadata": {
        "id": "bIVvXszfCoot"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train,transform_test=getAugmentation(img_size)\n",
        "trainset,trainloader,testset,testloader,num_classes=getData(bs, transform_train, transform_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cai6a9ZF8Go",
        "outputId": "7ba31cbc-28d6-40a3-fde5-fb952ec30020"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True  )\n",
        "data = cifar_trainset.data / 255 # data is numpy array\n",
        "\n",
        "mean = data.mean(axis = (0,1,2))\n",
        "std = data.std(axis = (0,1,2))\n",
        "print(f\"Mean : {mean}   STD: {std}\") #Mean : [0.491 0.482 0.446]   STD: [0.247 0.243 0.261]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi8dvhJwQzTK",
        "outputId": "9b203071-a454-412c-d528-80b5828c3144"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Mean : [0.49139968 0.48215841 0.44653091]   STD: [0.24703223 0.24348513 0.26158784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW269MMEKjC6",
        "outputId": "3d21ea50-9f14-46d5-8127-60a6e881a3c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.6196, 0.6157, 0.6118],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.6000, 0.5961, 0.5922],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.5804, 0.5765, 0.5725],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              " \n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.5176, 0.5137, 0.5098],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.4941, 0.4902, 0.4863],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.4667, 0.4627, 0.4627],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
              " \n",
              "         [[0.0000, 0.0000, 0.0000,  ..., 0.4235, 0.4196, 0.4157],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.3922, 0.3882, 0.3882],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.3647, 0.3608, 0.3569],\n",
              "          ...,\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]),\n",
              " 6)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "feature_extractor = AutoImageProcessor.from_pretrained(model_name_or_path)\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name_or_path)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "oYCyHbu7GhbQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoConfig\n",
        "config = AutoConfig.from_pretrained(model_name_or_path)\n",
        "d_model = config.hidden_size\n",
        "\n",
        "print(\"El valor de d_model es:\", d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KUJu9S7KtHC",
        "outputId": "86ad144c-62bd-4c1a-c333-fc92d8c60fdc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El valor de d_model es: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class modelViT(nn.Module):\n",
        "\n",
        "    def __init__(self, ViT, d_model, num_classes):\n",
        "\n",
        "        super(modelViT, self).__init__()\n",
        "        self.d_model=d_model\n",
        "        self.num_classes=num_classes\n",
        "\n",
        "        self.ViT = ViT\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(d_model),\n",
        "            nn.Linear(d_model, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        x = self.ViT(data)\n",
        "        last_hidden_state = x[\"last_hidden_state\"]\n",
        "        x = last_hidden_state.mean(dim=1)\n",
        "        x = self.mlp_head(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "C9nT3p2EHn4_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelViT(model, d_model, num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "J5FZffCFLpF3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el optimizador\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00005)\n",
        "# Se crea la funcion de perdida en base a esos pesos\n",
        "mse_loss = torch.nn.CrossEntropyLoss()\n",
        "epochs = 4\n",
        "best_acc = 0.0\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=1e-5)"
      ],
      "metadata": {
        "id": "lehlxToGMEu-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para entrenar el modelo\n",
        "def train():\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # lista de predicciones\n",
        "  total_preds=[]\n",
        "\n",
        "  # Se itera sobre los batches\n",
        "  for step,batch in enumerate(trainloader):\n",
        "    data, labels = batch\n",
        "    data = data.to(device)\n",
        "    labels = labels.to(device)\n",
        "    features = feature_extractor(data,  return_tensors='pt', do_rescale=False)  # extract features\n",
        "    features=features['pixel_values']\n",
        "    features= features.to(device)\n",
        "\n",
        "    # Se obtienen las predicciones del modelo\n",
        "    preds = model(features)\n",
        "    loss = mse_loss(preds, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    total_loss += loss.item()\n",
        "    _, predicted = preds.max(1)\n",
        "\n",
        "    total += labels.size(0)\n",
        "    correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    print('\\r %d %d -- Loss: %.3f | Acc: %.2f%%' % (step+1, len(trainloader), total_loss/(step+1), 100.*correct/total), end=\"\")\n",
        "\n",
        "  return total_loss/(step+1),100.*correct/total"
      ],
      "metadata": {
        "id": "2np_X3_LBG0r"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para entrenar el modelo\n",
        "def test():\n",
        "  global best_acc\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Se itera sobre los batches\n",
        "    for step,batch in enumerate(testloader):\n",
        "      data, labels = batch\n",
        "      data = data.to(device)\n",
        "      labels = labels.to(device)\n",
        "      features = feature_extractor(data,  return_tensors='pt', do_rescale=False)  # extract features\n",
        "      features=features['pixel_values']\n",
        "      features= features.to(device)\n",
        "\n",
        "      # Se obtienen las predicciones del modelo\n",
        "      preds = model(features)\n",
        "      loss = mse_loss(preds, labels)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = preds.max(1)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "      print('\\r %d %d -- Loss: %.3f | Acc: %.2f%%' % (step+1, len(testloader), test_loss/(step+1), 100.*correct/total), end=\"\")\n",
        "\n",
        "  # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print(\"\")\n",
        "        print('Saving checkpoint..')\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': test_loss,\n",
        "            'acc': acc}, './checkpoint/vit-ckpt.t7')\n",
        "        best_acc = acc\n",
        "  return test_loss/(step+1),100.*correct/total"
      ],
      "metadata": {
        "id": "Z5HydqFQEUh3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    print('\\n============ Epoch: %d ==============' % epoch)\n",
        "    print()\n",
        "\n",
        "    print(\"Training, lr= %f\" %(optimizer.param_groups[0]['lr']))\n",
        "    trainloss,acc = train()\n",
        "    print(\"\")\n",
        "\n",
        "    print(\"Validation, best acc=%f\" %(best_acc))\n",
        "    val_loss, acc = test()\n",
        "    print(\"\")\n",
        "\n",
        "    #scheduler.step(trainloss) # step scheduling\n",
        "    scheduler.step() # step scheduling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIyXxXrYGH0r",
        "outputId": "b31f623f-6123-47eb-87a2-89bff610f3a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============ Epoch: 0 ==============\n",
            "\n",
            "Training, lr= 0.000050\n",
            " 1563 1563 -- Loss: 0.542 | Acc: 88.80%\n",
            "Validation, best acc=0.000000\n",
            " 100 100 -- Loss: 0.221 | Acc: 95.34%\n",
            "Saving checkpoint..\n",
            "\n",
            "\n",
            "============ Epoch: 1 ==============\n",
            "\n",
            "Training, lr= 0.000044\n",
            " 1563 1563 -- Loss: 0.151 | Acc: 96.44%\n",
            "Validation, best acc=95.340000\n",
            " 100 100 -- Loss: 0.158 | Acc: 95.97%\n",
            "Saving checkpoint..\n",
            "\n",
            "\n",
            "============ Epoch: 2 ==============\n",
            "\n",
            "Training, lr= 0.000030\n",
            " 1563 1563 -- Loss: 0.122 | Acc: 96.70%\n",
            "Validation, best acc=95.970000\n",
            " 100 100 -- Loss: 0.141 | Acc: 96.29%\n",
            "Saving checkpoint..\n",
            "\n",
            "\n",
            "============ Epoch: 3 ==============\n",
            "\n",
            "Training, lr= 0.000016\n",
            " 1563 1563 -- Loss: 0.112 | Acc: 96.91%\n",
            "Validation, best acc=96.290000\n",
            " 100 100 -- Loss: 0.136 | Acc: 96.35%\n",
            "Saving checkpoint..\n",
            "\n"
          ]
        }
      ]
    }
  ]
}